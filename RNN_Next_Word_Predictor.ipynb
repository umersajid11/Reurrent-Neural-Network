{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "JKTIp39eXUah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "You're the light, you're the night\n",
        "You're the colour of my blood\n",
        "You're the cure, you're the pain\n",
        "You're the only thing I wanna touch\n",
        "Never knew that it could mean so much, so much\n",
        "You're the fear, I don't care\n",
        "'Cause I've never been so high\n",
        "Follow me through the dark\n",
        "Let me take you past the satellites\n",
        "You can see the world you brought to life, to life\n",
        "So love me like you do, lo-lo-love me like you do\n",
        "Love me like you do, lo-lo-love me like you do\n",
        "Touch me like you do, to-to-touch me like you do\n",
        "What are you waiting for?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "uinBlyDyXZmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.lower().replace(\"\\n\", \" \")"
      ],
      "metadata": {
        "id": "jfnFn3l6XeCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (text)"
      ],
      "metadata": {
        "id": "GVBD86GgYxCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1  # +1 because index starts from 1\n",
        "\n",
        "print(\"Vocabulary Size:\", total_words)\n",
        "print(\"Word Index Mapping:\", tokenizer.word_index)\n",
        "\n"
      ],
      "metadata": {
        "id": "FUa-Vn2dYv63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert entire text into sequence of integers\n",
        "tokens = tokenizer.texts_to_sequences([text])[0]\n",
        "print(\"Tokenized sequence:\", tokens[:20])  # show first 20 tokens"
      ],
      "metadata": {
        "id": "6G5PLoHHZGmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Create input sequences and targets\n",
        "# ===============================\n",
        "input_sequences = []\n",
        "seq_length = 5  # how many words in input sequence\n",
        "\n",
        "for i in range(seq_length, len(tokens)):\n",
        "    seq = tokens[i-seq_length:i]  # previous words (input)\n",
        "    target = tokens[i]            # next word (label)\n",
        "    input_sequences.append(seq + [target])\n",
        "\n",
        "input_sequences = np.array(input_sequences)\n",
        "\n",
        "# Inputs (X) are first n-1 words, targets (y) are last word\n",
        "X = input_sequences[:, :-1]\n",
        "y = input_sequences[:, -1]\n"
      ],
      "metadata": {
        "id": "CgO5o262ZUqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Padding (ensures equal length sequences)\n",
        "# ===============================\n",
        "X = pad_sequences(X, maxlen=seq_length, padding='pre')\n",
        "\n",
        "print(\"Example Input (token IDs):\", X[0])\n",
        "print(\"Example Target (token ID):\", y[0])"
      ],
      "metadata": {
        "id": "p88yHTD3Zbo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Build the Model\n",
        "# ===============================\n",
        "model = Sequential([\n",
        "    Embedding(total_words, 10, input_length=seq_length),  # 10-dim embedding\n",
        "    SimpleRNN(50, activation='tanh'),                    # Vanilla RNN layer\n",
        "    Dense(total_words, activation='softmax')             # Predict word probabilities\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "HoCN9lYPZh9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Train the Model\n",
        "# ===============================\n",
        "model.fit(X, y, epochs=500, verbose=1)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fEDGbIcRZos3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Text Generation Function\n",
        "# ===============================\n",
        "def generate_text(seed_text, next_words=20):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=seq_length, padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)[0]\n",
        "\n",
        "        # Map back to word\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                seed_text += \" \" + word\n",
        "                break\n",
        "    return seed_text"
      ],
      "metadata": {
        "id": "-lziU1CzZ7ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Try generating text\n",
        "# ===============================\n",
        "print(generate_text(\"you're the light\", 15))"
      ],
      "metadata": {
        "id": "1TO21XiYZ94e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}